{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train.csv', index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 333 entries, 1 to 506\n",
      "Data columns (total 14 columns):\n",
      "crim       333 non-null float64\n",
      "zn         333 non-null float64\n",
      "indus      333 non-null float64\n",
      "chas       333 non-null int64\n",
      "nox        333 non-null float64\n",
      "rm         333 non-null float64\n",
      "age        333 non-null float64\n",
      "dis        333 non-null float64\n",
      "rad        333 non-null int64\n",
      "tax        333 non-null int64\n",
      "ptratio    333 non-null float64\n",
      "black      333 non-null float64\n",
      "lstat      333 non-null float64\n",
      "medv       333 non-null float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 39.0 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df[:222]\n",
    "test = train_df[222:]\n",
    "\n",
    "train[['medv','crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat']].to_csv('./train_headless.csv', index=False, header=False)\n",
    "test[['medv','crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat']].to_csv('./valid_headless.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crim = tf.feature_column.numeric_column('crim', dtype=tf.float64)\n",
    "zn = tf.feature_column.numeric_column('zn', dtype=tf.float64)\n",
    "indus = tf.feature_column.numeric_column('indus', dtype=tf.float64)\n",
    "chas = tf.feature_column.numeric_column('chas', dtype=tf.int64)\n",
    "nox = tf.feature_column.numeric_column('nox', dtype=tf.float64)\n",
    "rm = tf.feature_column.numeric_column('rm', dtype=tf.float64)\n",
    "age = tf.feature_column.numeric_column('age', dtype=tf.float64)\n",
    "dis = tf.feature_column.numeric_column('dis', dtype=tf.float64)\n",
    "rad = tf.feature_column.numeric_column('rad', dtype=tf.int64)\n",
    "tax = tf.feature_column.numeric_column('tax', dtype=tf.int64)\n",
    "ptratio = tf.feature_column.numeric_column('ptratio', dtype=tf.float64)\n",
    "black = tf.feature_column.numeric_column('black', dtype=tf.float64)\n",
    "lstat = tf.feature_column.numeric_column('lstat', dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [crim, zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, black, lstat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for Input Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMNS = ['medv', 'crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat']\n",
    "LABEL_COLUMN = 'medv'\n",
    "DEFAULTS = [[0.0], [0.0], [0.0], [0.0], [0], [0.0], [0.0], [0.0], [0.0], [0], [0], [0.0], [0.0], [0.0]]\n",
    "\n",
    "def read_dataset(filename, mode, batch_size = 16):\n",
    "  def _input_fn():\n",
    "    def decode_csv(value_column):\n",
    "      columns = tf.decode_csv(value_column, record_defaults = DEFAULTS)\n",
    "      features = dict(zip(CSV_COLUMNS, columns))\n",
    "      label = features.pop(LABEL_COLUMN)\n",
    "      return features, label\n",
    "\n",
    "    # Create list of files that match pattern\n",
    "    file_list = tf.gfile.Glob(filename)\n",
    "\n",
    "    # Create dataset from file list\n",
    "    dataset = tf.data.TextLineDataset(file_list).map(decode_csv)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        num_epochs = None # indefinitely\n",
    "        dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "    else:\n",
    "        num_epochs = 1 # end-of-input after this\n",
    "\n",
    "    dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "  feature_placeholders = {\n",
    "    'crim' : tf.placeholder(tf.float64, [None]),\n",
    "    'zn' : tf.placeholder(tf.float64, [None]),\n",
    "    'indus' : tf.placeholder(tf.float64, [None]),\n",
    "    'chas' : tf.placeholder(tf.int64, [None]),\n",
    "    'nox' : tf.placeholder(tf.float64, [None]),\n",
    "    'rm' : tf.placeholder(tf.float64, [None]),\n",
    "    'age' : tf.placeholder(tf.float64, [None]),\n",
    "    'dis' : tf.placeholder(tf.float64, [None]),\n",
    "    'rad' : tf.placeholder(tf.int64, [None]),\n",
    "    'tax' : tf.placeholder(tf.int64, [None]),\n",
    "    'ptratio' : tf.placeholder(tf.float64, [None]),\n",
    "    'black' : tf.placeholder(tf.float64, [None]),\n",
    "    'lstat' : tf.placeholder(tf.float64, [None])\n",
    "  }\n",
    "  features = {\n",
    "      key: tf.expand_dims(tensor, -1)\n",
    "      for key, tensor in feature_placeholders.items()\n",
    "  }\n",
    "  return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "  estimator = tf.estimator.LinearRegressor(\n",
    "                       model_dir = output_dir,\n",
    "                       feature_columns = feature_cols)\n",
    "  train_spec=tf.estimator.TrainSpec(\n",
    "                       input_fn = read_dataset('./train_headless.csv', mode = tf.estimator.ModeKeys.TRAIN),\n",
    "                       max_steps = num_train_steps)\n",
    "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "  eval_spec=tf.estimator.EvalSpec(\n",
    "                       input_fn = read_dataset('./valid_headless.csv', mode = tf.estimator.ModeKeys.EVAL),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 1, # start evaluating after N seconds\n",
    "                       throttle_secs = 10,  # evaluate every N seconds\n",
    "                       exporters = exporter)\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'boston_trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x109d99cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 10 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into boston_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 11110.26, step = 1\n",
      "INFO:tensorflow:global_step/sec: 146.784\n",
      "INFO:tensorflow:loss = 1287.9409, step = 101 (0.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.056\n",
      "INFO:tensorflow:loss = 784.0472, step = 201 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.362\n",
      "INFO:tensorflow:loss = 704.6626, step = 301 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.4981\n",
      "INFO:tensorflow:loss = 1547.3442, step = 401 (1.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.132\n",
      "INFO:tensorflow:loss = 109.28975, step = 501 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.27\n",
      "INFO:tensorflow:loss = 424.97565, step = 601 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.206\n",
      "INFO:tensorflow:loss = 367.76926, step = 701 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.993\n",
      "INFO:tensorflow:loss = 380.46033, step = 801 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.494\n",
      "INFO:tensorflow:loss = 410.95892, step = 901 (0.768 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into boston_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 357.05566.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-15-04:06:21\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from boston_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-15-04:06:21\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 245.75482, global_step = 1000, loss = 3896.9692\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'crim': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float64>, 'zn': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float64>, 'indus': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float64>, 'chas': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=int64>, 'nox': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float64>, 'rm': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=float64>, 'age': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=float64>, 'dis': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=float64>, 'rad': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=int64>, 'tax': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=int64>, 'ptratio': <tf.Tensor 'Placeholder_10:0' shape=(?,) dtype=float64>, 'black': <tf.Tensor 'Placeholder_11:0' shape=(?,) dtype=float64>, 'lstat': <tf.Tensor 'Placeholder_12:0' shape=(?,) dtype=float64>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'crim': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float64>, 'zn': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float64>, 'indus': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float64>, 'chas': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=int64>, 'nox': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float64>, 'rm': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=float64>, 'age': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=float64>, 'dis': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=float64>, 'rad': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=int64>, 'tax': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=int64>, 'ptratio': <tf.Tensor 'Placeholder_10:0' shape=(?,) dtype=float64>, 'black': <tf.Tensor 'Placeholder_11:0' shape=(?,) dtype=float64>, 'lstat': <tf.Tensor 'Placeholder_12:0' shape=(?,) dtype=float64>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from boston_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"boston_trained/export/exporter/temp-b'1534305982'/saved_model.pb\"\n"
     ]
    }
   ],
   "source": [
    "# Run training    \n",
    "OUTDIR = 'boston_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "train_and_evaluate(OUTDIR, num_train_steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        crim   zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
      "ID                                                                              \n",
      "337  0.03427  0.0   5.19     0  0.515  5.869  46.3  5.2311    5  224     20.2   \n",
      "\n",
      "     black  lstat  medv  \n",
      "ID                       \n",
      "337  396.9    9.8  19.5  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('./test.csv', index_col='ID')\n",
    "print(test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./test_2.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./test_2.json\n",
    "{\"crim\":0.03427, \"zn\": 0.0, \"indus\": 5.19, \"chas\": 0, \"nox\": 0.515, \"rm\": 5.869, \"age\": 46.3, \"dis\": 5.2311, \"rad\": 5, \"tax\": 224, \"ptratio\": 20.2, \"black\": 396.9, \"lstat\": 9.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "ModuleNotFoundError: No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -c 'import tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Running [gcloud.ml-engine.local.predict] with arguments: [--json-instances: \"./test_2.json\", --model-dir: \"./boston_trained/export/exporter/1534303990\", --verbosity: \"debug\"]\n",
      "DEBUG: (gcloud.ml-engine.local.predict) Cannot import Tensorflow. Please verify \"python -c 'import tensorflow'\" works.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/robert/google-cloud-sdk/lib/googlecloudsdk/calliope/cli.py\", line 848, in Execute\n",
      "    resources = calliope_command.Run(cli=self, args=args)\n",
      "  File \"/Users/robert/google-cloud-sdk/lib/googlecloudsdk/calliope/backend.py\", line 770, in Run\n",
      "    resources = command_instance.Run(args)\n",
      "  File \"/Users/robert/google-cloud-sdk/lib/surface/ml_engine/local/predict.py\", line 76, in Run\n",
      "    framework=framework_flag)\n",
      "  File \"/Users/robert/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/local_utils.py\", line 101, in RunPredict\n",
      "    raise LocalPredictRuntimeError(err)\n",
      "LocalPredictRuntimeError: Cannot import Tensorflow. Please verify \"python -c 'import tensorflow'\" works.\n",
      "\n",
      "ERROR: (gcloud.ml-engine.local.predict) Cannot import Tensorflow. Please verify \"python -c 'import tensorflow'\" works.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ml-engine local predict --model-dir=./boston_trained/export/exporter/1534303990 --json-instances=./test_2.json --verbosity debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/robert/Documents/Kaggle/Boston\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $PWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1534303982\n",
      "1534303990\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls $PWD/boston_trained/export/exporter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.ml-engine.local.predict) unrecognized arguments: 1534303990\n",
      "Usage: gcloud ml-engine local predict --model-dir=MODEL_DIR (--json-instances=JSON_INSTANCES | --text-instances=TEXT_INSTANCES) [optional flags]\n",
      "  optional flags may be  --framework | --help | --json-instances |\n",
      "                         --text-instances\n",
      "\n",
      "For detailed information on this command and its flags, run:\n",
      "  gcloud ml-engine local predict --help\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "model_dir=$(ls ${PWD}/boston_trained/export/exporter)\n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=${PWD}/boston_trained/export/exporter/${model_dir} \\\n",
    "    --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-23bbf5830518>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'estimator' is not defined"
     ]
    }
   ],
   "source": [
    "preds = estimator.predict(input_fn=val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([item['predictions'][0] for item in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
